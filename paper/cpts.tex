% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
  a4paper,
]{article}

\usepackage{amsmath,amssymb}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}
\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
  
\fi
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{3}


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{todonotes}
\usepackage{orcidlink}
\definecolor{mypink}{RGB}{219, 48, 122}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[section]
\newtheorem{refsolution}{Solution}[section]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[style=authoryear-comp,]{biblatex}
\addbibresource{references.bib}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Online conformal inference for multi-step time series forecasting},
  pdfauthor={Xiaoqian Wang; Rob J Hyndman},
  pdfkeywords={Conformal prediction, Coverage
guarantee, Distribution-free inference, Exchangeability, Weighted
quantile estimate},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

%% CAPTIONS
\usepackage{caption}
\DeclareCaptionStyle{italic}[justification=centering]
 {labelfont={bf},textfont={it},labelsep=colon}
\captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
\captionsetup[table]{style=italic,format=hang,singlelinecheck=true}

%% FONT
\usepackage{bera}
\usepackage[charter]{mathdesign}
\usepackage[scale=0.9]{sourcecodepro}
\usepackage[lf,t]{FiraSans}

%% HEADERS AND FOOTERS
\usepackage{fancyhdr}
\pagestyle{fancy}
\rfoot{\Large\sffamily\raisebox{-0.1cm}{\textbf{\thepage}}}
\makeatletter
\lhead{\textsf{\expandafter{\@title}}}
\makeatother
\rhead{}
\cfoot{}
\setlength{\headheight}{15pt}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancypagestyle{plain}{%
\fancyhf{} % clear all header and footer fields
\fancyfoot[C]{\sffamily\thepage} % except the center
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

%% MATHS
\usepackage{bm,amsmath}
\allowdisplaybreaks

%% GRAPHICS
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.8}

%% SECTION TITLES
\usepackage[compact,sf,bf]{titlesec}
\titleformat{\section}[block]
  {\fontsize{15}{17}\bfseries\sffamily}
  {\thesection}
  {0.4em}{}
\titleformat{\subsection}[block]
  {\fontsize{12}{14}\bfseries\sffamily}
  {\thesubsection}
  {0.4em}{}
\titlespacing{\section}{0pt}{*5}{*1}
\titlespacing{\subsection}{0pt}{*2}{*0.2}

%% BIBLIOGRAPHY.

\makeatletter
\@ifpackageloaded{biblatex}{
\ExecuteBibliographyOptions{bibencoding=utf8,minnames=1,maxnames=3, maxbibnames=99,dashed=false,terseinits=true,giveninits=true,uniquename=false,uniquelist=false,doi=false, isbn=false,url=true,sortcites=false}
\DeclareFieldFormat{url}{\texttt{\url{#1}}}
\DeclareFieldFormat[article]{pages}{#1}
\DeclareFieldFormat[inproceedings]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[incollection]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{title}{\MakeCapital{#1}}
\DeclareFieldFormat[article]{url}{}
\DeclareFieldFormat[inproceedings]{title}{#1}
\DeclareFieldFormat{shorthandwidth}{#1}
\usepackage{xpatch}
\xpatchbibmacro{volume+number+eid}{\setunit*{\adddot}}{}{}{}
% Remove In: for an article.
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{%
  \printtext{\bibstring{in}\intitlepunct}}}
\AtEveryBibitem{\clearfield{month}}
\AtEveryCitekey{\clearfield{month}}
\DeclareDelimFormat[cbx@textcite]{nameyeardelim}{\addspace}
\renewcommand*{\finalnamedelim}{\addspace\&\space}
}{}
\makeatother

%% PAGE BREAKING to avoid widows and orphans
\clubpenalty = 2000
\widowpenalty = 2000
\usepackage{microtype}
% Placement of logos

\RequirePackage[absolute,overlay]{textpos}
\setlength{\TPHorizModule}{1cm}
\setlength{\TPVertModule}{1cm}
\def\placefig#1#2#3#4{\begin{textblock}{.1}(#1,#2)\rlap{\includegraphics[#3]{#4}}\end{textblock}}

% Title and date

\title{Online conformal inference for multi-step time series
forecasting}
\date{20 September 2024}

\def\Date{\number\day}
\def\Month{\ifcase\month\or
 January\or February\or March\or April\or May\or June\or
 July\or August\or September\or October\or November\or December\fi}
\def\Year{\number\year}

% Working paper number and JEL codes

\makeatletter
\def\wp#1{\gdef\@wp{#1}}\def\@wp{??/??}
\def\jel#1{\gdef\@jel{#1}}\def\@jel{??}
\def\showjel{{\large\textsf{\textbf{JEL classification:}}~\@jel}}
\def\nojel{\def\showjel{}}
\makeatother

\wp{no/yr}
\jel{C10,C14,C32}

% Title page

\makeatletter
\def\cover{{\sffamily\setcounter{page}{0}
        \thispagestyle{empty}
        \placefig{2}{1.5}{width=5cm}{monash2}
        \placefig{16.9}{1.5}{width=2.1cm}{MBSportrait}
        \begin{textblock}{4}(16.9,4)ISSN 1440-771X\end{textblock}
        \begin{textblock}{7}(12.7,27.9)\hfill
        \includegraphics[height=0.7cm]{AACSB}~~~
        \includegraphics[height=0.7cm]{EQUIS}~~~
        \includegraphics[height=0.7cm]{AMBA}
        \end{textblock}
        \vspace*{2.5cm}
        \begin{center}\Large
        Department of Econometrics and Business Statistics\\[.5cm]
        \footnotesize http://monash.edu/business/ebs/research/publications
        \end{center}\vspace{2cm}
        \begin{center}
        \fbox{\parbox{14cm}{\begin{onehalfspace}\centering\Huge\vspace*{0.3cm}
                \textsf{\textbf{\expandafter{\@title}}}\vspace{1cm}\par
                \LARGE
                \expandafter{\@author}
                \end{onehalfspace}
        }}
        \end{center}
        \vfill
                \begin{center}\Large
                \Month~\Year\\[1cm]
                Working Paper \@wp
        \end{center}\vspace*{2cm}}}
        \def\addresses#1{\gdef\@addresses{#1}}\def\@addresses{??}
        \def\pageone{{\sffamily\setstretch{1}%
        \thispagestyle{empty}%
        \vbox to \textheight{%
        \raggedright\baselineskip=1.2cm
     {\fontsize{24.88}{30}\sffamily\textbf{\expandafter{\@title}}}
        \vspace{2cm}\par
        \hspace{1cm}\parbox{14cm}{\sffamily\large\@addresses}\vspace{1cm}\vfill
        \hspace{1cm}{\large\Date~\Month~\Year}\\[1cm]
        \hspace{1cm}\showjel\vss}}}
\def\blindtitle{{\sffamily
     \thispagestyle{plain}\raggedright\baselineskip=1.2cm
     {\fontsize{24.88}{30}\sffamily\textbf{\expandafter{\@title}}}\vspace{1cm}\par
        }}
\def\titlepage{{\cover\newpage\pageone\newpage\blindtitle}}

\def\blind{\def\titlepage{{\blindtitle}}\let\maketitle\blindtitle}
\def\titlepageonly{\def\titlepage{{\pageone\end{document}}}}
\def\nocover{\def\titlepage{{\pageone\newpage\blindtitle}}\let\maketitle\titlepage}
\let\maketitle\titlepage
\makeatother

% Authors

\nocover
  \author{Xiaoqian Wang, Rob J Hyndman}
  \addresses{%
    %
      \textbf{Xiaoqian Wang}\\%
      %
        Department of Econometrics \& Business Statistics\\%
        Monash University\\%
        Clayton VIC 3800\\%
        Australia\\%
      %
      {Email: xiaoqian.wang@monash.edu}\\%
      \textit{Corresponding author}\\[0.5cm]%
   %
      \textbf{Rob J Hyndman}\\%
      %
        Department of Econometrics \& Business Statistics\\%
        Monash University\\%
        Clayton VIC 3800\\%
        Australia\\%
      %
      {Email: rob.hyndman@monash.edu}\\%
      \\[0.5cm]%
   %
   }%
   \lfoot{\sf Wang, Hyndman: 20 September 2024}

% Keywords

\newenvironment{keywords}{\par\vspace{0.5cm}\noindent{\sffamily\textbf{Keywords:}}}{\vspace{0.25cm}\par\hrule\vspace{0.5cm}\par}

% Abstract
\renewenvironment{abstract}{\begin{minipage}{\textwidth}\parskip=1.4ex\noindent
\hrule\vspace{0.1cm}\par{\sffamily\textbf{\abstractname}}\newline\setstretch{1}}
  {\end{minipage}}
\begin{document}
\maketitle

\begin{abstract}
We consider the problem of constructing distribution-free prediction
intervals for multi-step time series forecasting, with a focus on the
temporal dependencies inherent in multi-step forecast errors. We
establish that the forecast errors of optimal multi-step forecasts can
be approximated by an autoregressive process under a general
non-stationary autoregressive data generating process. To leverage these
properties, we propose the Autocorrelated Multi-step Conformal
Prediction (AcMCP) method, which effectively incorporates
autocorrelations in multi-step forecast errors, resulting in more
logically structured prediction intervals. This method ensures
theoretical long-run coverage guarantees for multi-step forecasts,
although we note that increased forecasting horizons may exacerbate
deviations from the target coverage, particularly in the context of
limited sample sizes. Additionally, we extend several easy-to-implement
conformal prediction methods originally designed for single-step
forecasting to accommodate multi-step scenarios. Through empirical
evaluations, including simulations and real-world case studies, we
demonstrate that AcMCP achieves coverage that closely aligns with the
target within local windows, while providing adaptive prediction
intervals that adjust effectively to varying conditions.
\end{abstract}

\begin{keywords}
  Conformal prediction; Coverage guarantee; Distribution-free
inference; Exchangeability; 
  Weighted quantile estimate.
\end{keywords}


\setstretch{1}
\section{Introduction}\label{sec-intro}

Conformal prediction \autocite{vovk2005} stands as a powerful and
flexible tool for uncertainty quantification, distinguished by its
simplicity, generality, and ease of implementation. It constructs valid
prediction intervals that achieve nominal coverage without imposing
stringent assumptions on the data generating distribution, other than
requiring the data to be i.i.d. or, more generally, exchangeable. Its
credibility and potential make it widely applicable for quantifying the
uncertainty of forecasts produced by any black-box machine learning
model \autocite{shafer2008,papadopoulos2008,barber2021} or
non-parametric model \autocite{lei2014}.

Three key classes of conformal prediction methods are widely used for
constructing distribution-free prediction intervals, i.e., split
conformal prediction \autocite{vovk2005}, full conformal prediction
\autocite{vovk2005}, and jackknife+ \autocite{barber2021}. The split
conformal method, which relies on a holdout set, offers computational
efficiency but sacrifices some statistical accuracy due to data
splitting. In contrast, full conformal prediction avoids data splitting,
providing higher accuracy at the cost of increased computational
complexity. Jackknife+ strikes a balance between these methods, offering
a compromise between statistical precision and computational demands.
All three methods guarantee coverage at the target level under the
assumption of data exchangeability.

Nevertheless, the data exchangeability assumption is often violated in
real-world contexts, where challenges such as non-stationarity,
distributional drift, temporal and spatial dependencies are prevalent.
In response, several extensions to conformal prediction have been
proposed to accommodate non-exchangeable data. Notable examples include
methods for handling covariate shift
\autocite{tibshirani2019,lei2021,yang2024}, online distribution shift
\autocite{gibbs2021,zaffran2022,bastani2022}, label shift
\autocite{podkopaev2021}, time series data
\autocite{chernozhukov2018,gibbs2021,xu2021,xu2023,zaffran2022}, and
spatial prediction \autocite{mao2024}, and methods based on certain
distributional assumptions of the data rather than exchangeability
\autocite{oliveira2024,xu2021,xu2023}. Additionally, some methods
propose weighting the nonconformity scores differently, either using
non-data-dependent weights \autocite{barber2023} or weights based on
observed feature values \autocite{tibshirani2019,guan2023,hore2023}.

Recently, several attempts have been made to enable conformal prediction
on time series data, where exchangeability obviously fails due to
inherent temporal dependencies. One line of research has focused on
developing conformal-type methods that offer coverage guarantees under
certain relaxations of exchangeability. For example, within the full
conformal prediction framework, \textcite{chernozhukov2018} and
\textcite{yu2022} construct prediction sets for time series by using a
group of permutations that are specifically designed to preserve the
dependence structure in the data, ensuring validity under weak
assumptions on the nonconformity score. In the split conformal
prediction framework, \textcite{xu2021} and \textcite{xu2023} extend
conformal prediction methods under classical nonparametric assumptions
to achieve asymptotic valid conditional coverage for time series.
\textcite{barber2023} use weighted residual distributions to provide
robustness against distribution drift. Additionally,
\textcite{oliveira2024} introduce a general framework based on
concentration inequalities and data decoupling properties of the data to
retain asymptotic coverage guarantees across several dependent data
settings.

In a separate strand of research, \textcite{gibbs2021} develop adaptive
conformal inference in an online manner to manage temporal distribution
shifts and ensure long-run coverage guarantees. The basic idea is to
adapt the miscoverage rate, \(\alpha\), based on historical miscoverage
frequencies. Follow-up work has refined this idea by introducing
time-dependent step sizes to respond to arbitrary distribution shifts,
as seen in studies by \textcite{bastani2022}, \textcite{zaffran2022},
\textcite{gibbs2024}, and \textcite{angelopoulos2024online}. However,
these methods may produce prediction intervals that are either infinite
or null. To address this issue, recent research has proposed a
generalized updating process that tracks the quantile of the
nonconformity score sequence, as discussed by \textcite{bhatnagar2023},
\textcite{angelopoulos2024}, and \textcite{angelopoulos2024online}.

Existing conformal prediction methods for time series primarily focus on
single-step forecasting. However, many real-world problems require
forecasts for multiple future time steps, not just one. Related research
into multi-step time series forecasting is limited and does not account
for the temporal dependencies inherent in multi-step forecasts. For
example, \textcite{stankeviciute2021} integrate conformal prediction
with recurrent neural networks for multi-step forecasting and then apply
Bonferroni correction to achieve the desired coverage rate. This
approach, however, assumes data independence, which is not often
unrealistic for time series data. \textcite{yang2024ts} propose Bellman
conformal inference, an extension of adaptive conformal prediction, to
control multi-step miscoverage rates simultaneously at each time point
\(t\) by minimizing a loss function that balances the average interval
length across forecast horizons with miscoverage. While this method
considers multi-step intervals, it does not account for their temporal
dependencies and may be computationally intensive when solving the
associated optimization problems. Additionally, several extensions to
multivariate targets have been explored, see, e.g.,
\textcite{schlembach2022} and \textcite{sun2022}.

In this paper, we employ a unified notation to formalize the
mathematical representation of conformal prediction for time series
data. We consider a general sequential setting in which we observe a
time series \(\{y_t\}_{t \geq 1}\) generated by an unknown data
generating process (DGP), which may depend on its own past, along with
other exogenous predictors,
\(\bm{x}_t=(x_{1,t},\ldots,x_{p,t})^{\prime}\), and their histories. The
distribution of
\(\{(\bm{x}_t, y_t)\}_{t \geq 1} \subseteq \mathbb{R}^p \times \mathbb{R}\)
is obviously allowed to vary over time in time series context. At each
time point \(t\), we aim to forecast \(H\) steps into the future,
providing a \emph{prediction set} (which is a prediction interval in
this setting), \(\hat{\mathcal{C}}_{t+h|t}\), for the realization
\(y_{t+h}\) for each \(h\in[H]\). The \(h\)-step-ahead forecast uses the
previously observed data \(\{(\bm{x}_i, y_i)\}_{1 \leq i \leq t}\) along
with the new information of the exogenous predictors
\(\{\bm{x}_{t+j}\}_{1\leq j\leq h}\). Note that we can generate ex-ante
forecasts by using forecasts of the predictors based on information
available up to and including time \(t\). Alternatively, ex-post
forecasts are generated assuming that actual observations of the
predictors from the forecast period are available. Given a nominal
\emph{miscoverage rate} \(\alpha \in (0,1)\) specified by the user, we
expect the output \(\hat{\mathcal{C}}_{t+h|t}\) to be a \emph{valid}
prediction interval so that \(y_{t+h}\) falls within the prediction
interval \(\hat{\mathcal{C}}_{t+h|t}\) at least \(100(1-\alpha)\%\) of
the time.

Our goal is to achieve long-run coverage for multi-step univariate time
series forecasting. All the proposed methods are grounded in the split
conformal prediction framework and an online learning scheme, which are
well-suited to the sequential nature of time series data. First, we
extend several widely-used conformal prediction methods that are
originally designed for single-step forecasting to accommodate
multi-step forecasting scenarios. Second, we provide theoretical proofs
demonstrating that the forecast errors of optimal \(h\)-step-ahead
forecasts approximate an AR process when we assume a general
non-stationary autoregressive data generating process. Third, we
introduce the autocorrelated multi-step conformal prediction method,
which accounts for the autocorrelations of multi-step forecast errors.
Our method is proven to achieve long-run coverage guarantees without
making any assumptions on data distribution shifts. We also highlight
that for \(t \ll \infty\), increasing the forecast horizon \(h\)
generally leads to greater deviations from the target coverage, which
aligns with our expectations. Finally, we illustrate the practical
utility of these proposed methods through two simulations and two
real-data experiments on electricity demand and eating out expenditure
forecasting.

We developed the conformalForecast package for R, available at
\url{https://github.com/xqnwang/conformalForecast}, to implement the
proposed multi-step conformal prediction methods. All the data and code
to reproduce the experiments are made available at
\url{https://github.com/xqnwang/cpts}.

\section{Setup}\label{sec-setup}

In this paper, we consider multi-step time series forecasting problems.
Let \(z_t = (\bm{x}_t, y_t)\) denote the data point (including the
response and possibly predictors) at time \(t\). Suppose that, at each
time \(t\), we have a forecasting model \(\hat{f}_t\) trained using the
historical data \(z_{1:t}\). Throughout the paper, we assume that the
predictors are known into the future. In this way, we perform ex-post
forecasting and there is no additional uncertainty introduced from
forecasting the exogenous predictors. Using the forecasting model
\(\hat{f}_t\), we are able to produce \(H\)-step point forecasts,
\(\{\hat{y}_{t+h|t}\}_{h\in[H]}\), using the future values for the
predictors. The task is to employ conformal inference to build
\(H\)-step prediction intervals,
\(\{\hat{\mathcal{C}}_{t+h|t}^{\alpha}\left(z_{1:t},\bm{x}_{t+1:h}\right)\}_{h\in[H]}\),
at the target coverage level \(1-\alpha\). For brevity, we will use
\(\hat{\mathcal{C}}_{t+h|t}^{\alpha}\) to denote the \(h\)-step-ahead
\(100(1-\alpha)\%\) prediction interval.

\textbf{Sequential split.} In time series context, it is infeasible to
perform \emph{random splitting}, a standard strategy in much of the
conformal prediction literature, in split conformal due to the temporal
dependency present in the data. Instead, throughout the conformal
prediction methods proposed in this paper, we use a \emph{sequential
split} to preserve the temporal structure. For example, the \(t\)
available data points, \(z_{1:t}\), are sequentially split into two
consecutive sets, a \emph{proper training set}
\(\mathcal{D}_{\text{tr}} \subset \{1,\ldots,t_r\}\) and a
\emph{calibration set}
\(\mathcal{D}_{\text{cal}} \subset \{t_r+1,\ldots,t\}\), where
\(t_c=t-t_r \gg H\).

\textbf{Online learning.} Here we consider a generic online learning
framework to adapt to all conformal prediction methods we will discuss
in subsequent sections. This framework updates prediction intervals as
new data points arrive, allowing us to assess their long-run coverage
behavior. It adopts a standard rolling window evaluation strategy and
consists of the following steps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialization. Train a forecasting model on the initial proper
  training set \(z_{(1+t-t_r):t}\), setting \(t=t_r\). Then generate
  \(H\)-step point forecasts \(\{\hat{y}_{t+h|t}\}_{h\in[H]}\) and
  compute the corresponding nonconformity scores
  \(\{s_{t+h|t}=\mathcal{S}(z_{(1+t-t_r):t}, y_{t+h})\}_{h\in[H]}\)
  based on the true values \(H\) time steps ahead,
  i.e.~\(\{y_{t+h}\}_{h\in[H]}\).
\item
  Recurring procedure. Roll the training set forward by one data point
  by setting \(t \rightarrow t+1\). Then repeat the step 1 until the
  nonconformity scores on the entire initial calibration set,
  \(\{s_{t+h|t}\}_{t_r \leq t \leq t_r+t_c-h}\) for \(h\in[H]\), are
  computed.
\item
  Quantile estimation and prediction interval calculation. Use
  nonconformity scores obtained from the calibration set to perform
  quantile estimation and compute \(H\)-step prediction intervals on the
  test set.
\item
  Online updating. Continuously roll the training set and calibration
  set forward by one data point to update the nonconformity scores for
  calibration, and then repeat the step 3 until prediction intervals for
  the entire test set are obtained, i.e.,
  \(\{\hat{\mathcal{C}}_{t+h|t}^{\alpha}\}_{t_r+t_c \leq t \leq T-h}\)
  for \(h \in [H]\), where \(T-t_r-t_c\) is the length of the test set
  used for testing coverage. Therefore, our goal is to achieve long-run
  coverage in time.
\end{enumerate}

For simplicity, so far we have only presented the \emph{nonconformity
score} defined as the (signed) forecast error

\[
s_{t+h|t}=\mathcal{S}\left(z_{1:t}, y_{t+h}\right):=y_{t+h}-\hat{f}_t\left(z_{1:t},\bm{x}_{t+1:h}\right)=y_{t+h}-\hat{y}_{t+h|t},
\]

which is the most commonly used accuracy measure in the context of time
series forecasting. We also note that the online learning setting can
also be easily adjusted to work with expanding windows for the training
and calibration sets.

\textbf{Remark.} With sequential splitting, multiple \(H\)-step
forecasts and their respective nonconformity scores can be computed on
the calibration set. These nonconformity scores have diverse forecast
horizons, ranging from \(1\) to \(H\), i.e., the number of periods
between the forecast origin and the time at which nonconformity scores
are evaluated. Thus, we can not uniformly treat these nonconformity
scores and generate \(H\)-step prediction intervals of identical width.

\section{Related methods extensions to multi-step
forecasting}\label{sec-ext}

In this section, we extend several popular conformal prediction methods
to make them applicable to multi-step forecasting problems. One of the
key properties of optimal forecast errors is that the variance of the
forecast error \(e_{t+h|t}\) is non-decreasing in \(h\)
\autocite{diebold1996,patton2007}. Therefore, instead of uniformly
treating \(H\)-step nonconformity scores and generating \(H\)-step
prediction intervals of identical width, we consider a setting wherein a
separate conformal prediction procedure is applied for each
\(h \in [H]\) in an online manner.

\subsection{Online multi-step split conformal
prediction}\label{online-multi-step-split-conformal-prediction}

Split conformal prediction (SCP, also called inductive conformal
prediction, \textcite{papadopoulos2002}; \textcite{vovk2005};
\textcite{lei2018}), is a holdout method for building prediction
intervals using a pre-trained model in regression settings. A key
advantage of SCP is its ability to guarantee coverage by assuming data
exchangeability. Time series data are inherently nonexchangeable due to
their temporal dependence and autocorrelation. Therefore, directly
applying SCP to time series data would violate the method's
exchangeability assumption, thereby compromising its coverage guarantee.

Here we introduce online \textbf{multi-step split conformal prediction}
(MSCP) as a generalization of SCP to recursively update all \(H\)-step
prediction intervals over time. Instead of assuming exchangeability,
MSCP applys conformal inference in an online fashion, updating
prediction intervals as new data points are received. Specifically, for
each \(h \in [H]\), we consider the following simple online update to
construct prediction intervals on the test set:

\begin{equation}\phantomsection\label{eq-mscp}{
\hat{\mathcal{C}}_{t+h|t}^{\alpha} = \left\{y\in\mathbb{R}: s_{t+h|t}^{y} \leq Q_{1-\alpha}\left(\sum_{i=t-t_c+1}^{t}\frac{1}{t_c+1}\cdot\delta_{s_{i|i-h}}+\frac{1}{t_c+1}\cdot\delta_{+\infty}\right)\right\},
}\end{equation}

where \(s_{t+h|t}^{y}:=\mathcal{S}(z_{1:t}, y)\) denotes the
\(h\)-step-ahead nonconformity score calculated at time \(t\) using a
hypothesized test observation \(y\), \(\mathrm{Q}_\tau(\cdot)\) denotes
the \(\tau\)-quantile of its argument, and \(\delta_a\) denotes the
point mass at \(a\).

\subsection{Online multi-step weighted conformal
prediction}\label{online-multi-step-weighted-conformal-prediction}

In the regression setting, \textcite{barber2023} propose nonexchangeable
conformal prediction (NexCP) that generalizes the SCP method to allow
for some sources of nonexchangeability. The core idea is that a higher
weight should be assigned to a data point that is believed to originate
from the same distribution as the test data. Note that NexCP assumes the
weights are fixed and data-independent. When the data are exchangeable,
NexCP offers the same coverage guarantees as SCP, while the coverage gap
is characterized by the total variation between the swapped
nonconformity score vectors when exchangeability is violated. Thus the
coverage gap may be quite large in time series contexts.

The online \textbf{multi-step weighted conformal prediction} (MWCP)
method we propose here adapts the NexCP method to the online setting for
time series forecasting. MWCP uses weighted quantile estimate for
constructing prediction intervals, contrasting with the MSCP definitions
where all nonconformity scores for calibration are implicitly assigned
equal weight.

We choose fixed weights \(w_i = b^{t+1-i}\), \(b \in (0, 1)\) and
\(i=t-t_c+1,\ldots,t\), for nonconformity scores on the corresponding
calibration set. In this setting, weights decay exponentially as the
nonconformity scores get order, akin to the rationale behind the
exponential smoothing method in time series forecasting. Then for each
\(h \in [H]\), MWCP consider the online update for \(h\)-step-ahead
prediction interval:

\[
\hat{\mathcal{C}}_{t+h|t}^{\alpha} = \left\{y\in\mathbb{R}: s_{t+h|t}^{y} \leq Q_{1-\alpha}\left(\sum_{i=t-t_c+1}^{t}\tilde{w}_i\cdot\delta_{s_{i|i-h}}+\tilde{w}_{t+1}\cdot\delta_{+\infty}\right)\right\},
\]

where \(\tilde{w}_i\) and \(\tilde{w}_{t+1}\) are normalized weights
given by

\[
\tilde{w}_i = \frac{w_i}{\sum_{i=t-t_c+1}^{t}w_i+1}, \text{ for } i \in \{t-t_c+1,\ldots,t\} \quad \text{and} \quad \tilde{w}_{t+1} =  \frac{1}{\sum_{i=t-t_c+1}^{t}w_i+1}.
\]

As suggested by \textcite{barber2023}, an exponential weighting scheme
can be applied for time series data, with weights decreasing
exponentially for data points that are coming from the further in the
past.

\subsection{Multi-step adaptive conformal
prediction}\label{multi-step-adaptive-conformal-prediction}

In the online learning framework outlined in Section~\ref{sec-setup}, we
extend the adaptive conformal prediction (ACP) method proposed by
\textcite{gibbs2021} to address multi-step time series forecasting,
introducing the \textbf{multi-step adaptive conformal prediction} (MACP)
method. Specifically, for each \(h \in [H]\), we treat \(\alpha\) as a
tunable parameter and iteratively estimate \(\alpha_{t+h|t}^{*}\)
(treated as a tunable parameter) using the update equation

\begin{equation}\phantomsection\label{eq-macp}{
\alpha_{t+h|t} := \alpha_{t+h-1|t-1} + \gamma\left(\alpha - \mathrm{err}_{t|t-h}\right).
}\end{equation}

Then the \(h\)-step-ahead prediction interval is computed using
Equation~\ref{eq-mscp} by setting \(\alpha = \alpha_{t+h|t}\). Here,
\(\gamma > 0\) denotes a fixed step size parameter, \(\alpha_{2h|h}\)
denotes the initial estimate typically set to \(\alpha\), and
\(\mathrm{err}_{t|t-h}\) denotes the miscoverage event
\(\mathrm{err}_{t|t-h} = \mathbb{1}\left\{y_t \notin \hat{\mathcal{C}}_{t|t-h}^{\alpha_{t|t-h}}\right\}\).

Equation~\ref{eq-macp} indicates that the correction to the estimation
of \(\alpha_{t+h|t}^{*}\) at time \(t+h\) is determined by the
historical miscoverage frequency up to time \(t\). At each iteration, we
raise the estimate of \(\alpha_{t+h|t}^{*}\) used for quantile
estimation at time \(t+h\) if
\(\hat{\mathcal{C}}_{t|t-h}^{\alpha_{t|t-h}}\) covered \(y_t\), whereas
we lower the estimate if \(\hat{\mathcal{C}}_{t|t-h}^{\alpha_{t|t-h}}\)
miscovered \(y_t\). Thus the miscoverage event has a delayed impact on
the estimation of \(\alpha_{t+h|t}^{*}\) over \(h\) periods, indicating
that the correction of the \(\alpha_{t+h|t}^{*}\) estimate becomes less
prompt with increasing values of \(h\). Particularly,
Equation~\ref{eq-macp} reduces to the update for ACP for \(h=1\).

We did not consider the update equation
\(\alpha_{t+1|t-h+1} := \alpha_{t|t-h} + \gamma\left(\alpha - \mathrm{err}_{t|t-h}\right)\)
in this context, as in this case the available information at time \(t\)
is insufficient to estimate \(\alpha_{t+h|t}^{*}\) used for forecasting
\(h\) steps.

Selecting the parameter \(\gamma\) is pivotal yet challenging.
\textcite{gibbs2021} suggest setting \(\gamma\) in proportion to the
degree of variation of the unknown \(\alpha_{t}^{*}\) over time. Several
strategies have been proposed to avoid the necessity of selecting
\(\gamma\). For example, \textcite{zaffran2022} use an adaptive
aggregation of multiple ACPs with a set of candidate values for
\(\gamma\) , determining weights based on their historical performance.
\textcite{bastani2022} propose a multivalid prediction algorithm in
which the prediction set is established by selecting a threshold from a
sequence of candidate thresholds. However, both previous methods fail to
promptly adapt to the local changes. To address this limitation,
\textcite{gibbs2024} suggest adaptively tuning the step size parameter
\(\gamma\) in an online setting, choosing an ``optimal'' value for
\(\gamma\) from a candidate set of values by assessing their historical
performance.

\textbf{Remark.} The theoretical coverage properties of ACP suggest that
a larger value for \(\gamma\) generally results in less deviation from
the target coverage. As there is no restriction on \(\alpha_{t+h|t}\)
and it can drift below \(0\) or above \(1\), a larger \(\gamma\) may
lead to frequent output of null or infinite prediction sets in order to
quickly adapt to the current miscoverage status.

\subsection{Multi-step conformal PID
control}\label{multi-step-conformal-pid-control}

We introduce \textbf{multi-step conformal PID control} method (hereafter
referred to as MPID), which extends the PID method
\autocite{angelopoulos2024}, originally developed for one-step-ahead
forecasting, to deal with multi-step time series forecasting.

For each individual forecast horizon \(h\in[H]\), the iteration of the
\(h\)-step-ahead quantile estimate is given by

\begin{equation}\phantomsection\label{eq-mpid}{
q_{t+h|t}=\underbrace{q_{t+h-1|t-1}+\eta \left(\mathrm{err}_{t|t-h}-\alpha\right)}_{\mathrm{P}}+\underbrace{r_t\left(\sum_{i=h+1}^t \left(\mathrm{err}_{i|i-h}-\alpha\right)\right)}_{\mathrm{I}}+\underbrace{\hat{s}_{t+h|t}}_{\mathrm{D}},
}\end{equation}

where, \(\eta > 0\) is a constant learning rate, and \(r_t\) is a
saturation function that adheres to the following conditions

\begin{equation}\phantomsection\label{eq-saturation_h}{
x \geq c \cdot g(t-h) \Longrightarrow r_t(x) \geq b, \quad \text {and} \quad x \leq-c \cdot g(t-h) \Longrightarrow r_t(x) \leq -b,
}\end{equation}

for constant \(b, c > 0\), and an admissible function \(g\) that is
sublinear, nonnegative, and nondecreasing. With this updating equation,
we can obtain all required \(h\)-step-ahead prediction intervals using
information available up to time \(t\). Notably, when \(h=1\),
Equation~\ref{eq-mpid} simplifies to the PID update, which guarantees
long-run coverage. More importantly, Equation~\ref{eq-mpid} represents a
specific instance of Equation~\ref{eq-acmcp_1} that we will introduce
later, thereby ensuring long-run coverage for each individual forecast
horizon \(h\) according to Proposition~\ref{prp-cov_acmcp}.

The P control in MPID shows a delayed correction of the quantile
estimate for a length of \(h\) periods. The underlying intuition is
similar to that of MACP: it increases (or decreases) the
\(h\)-step-ahead quantile estimate if the prediction set at time \(t\)
miscovered (or covered) the corresponding realization. MACP can be
considered as a special case of the P control, while the P control has
the ability to prevent the generation of null or infinite prediction
sets after a sequence of miscoverage events.

The I control accounts for the cumulative historical coverage errors
associated with \(h\)-step-ahead prediction intervals during the update
process, thereby enhancing the stability of the interval coverage.

The D control involves \(\hat{s}_{t+h|t}\) as the \(h\)-step-ahead
forecast of the nonconformity score (defined as the forecast error
here), produced by any suitable scorecaster (forecasting model) trained
using the \(h\)-step-ahead nonconformity scores available up to and
including time \(t\). This module, however, tends to result in increased
forecast variance for a larger forecast horizon \(h\).

\section{Autocorrelated multi-step conformal
prediction}\label{sec-acmcp}

In the PID method proposed by \textcite{angelopoulos2024}, a notable
feature is the inclusion of a scorecaster, a model trained on the score
sequence, to forecast the future score. The rationale behind it is to
residualize out any leftover signal in the score distribution not
captured by the base forecasting model, such as trend and seasonality.
However, in the context of time series forecasting, good forecasts are
essential for making good decisions. We naturally expect to use a good
forecasting model and ensure there is no useful signal in forecast
errors (defined as nonconformity scores in this paper). If the forecasts
are not optimal, the forecasting model should be improved to enhance its
performance. Hence, we typically assume the use of a good forecasting
model, and therefore, relying on another model to predict forecast
errors to capture leftover information is not a commonly applicable
solution. Moreover, the inclusion of a scorecaster often only introduces
variance to the quantile estimate, resulting in inefficient (wider)
prediction intervals.

On the other hand, in our general setup outlined in
Section~\ref{sec-setup}, the DGP of a time series may depend on its own
past, along with other exogenous predictors and their histories.
Consequently, the \(h\)-step-ahead forecast errors \(e_{t+h|t}\) may
depend on the forecast errors from the past \(h-1\) steps,
i.e.~\(e_{t+1|t}, \ldots, e_{t+h-1|t}\), and forecast errors may
accumulate over the forecast horizon. However, no conformal prediction
methods have taken this potential dependence into account in their
methodological construction.

In this section, we will explore the properties of multi-step forecast
errors and propose a novel conformal prediction method that considers
the autocorrelations of multi-step forecast errors.

\subsection{Properties of multi-step forecast errors}\label{sec-ppt}

We assume that a time series \(\{y_t\}_{t \geq 1}\) is generated by a
general non-stationary autoregressive process given by:

\begin{equation}\phantomsection\label{eq-dgp}{
y_t = f_{t}\left(y_{(t-d):(t-1)},\bm{x}_{(t-k):t}\right) + \epsilon_t,
}\end{equation}

where \(f_{t}\) is considered a nonlinear function in \(d\) lagged
values of \(y_t\) (i.e.~\(y_{(t-d):(t-1)}\)) and the current value along
with the preceding \(k\) values of the exogenous predictors
(i.e.~\(\bm{x}_{(t-k):t}\)), and \(\epsilon_t\) is white noise.

It is well-established in the forecasting literature that, for optimal
\(h\)-step-ahead forecasts, the sequence of forecast errors is \emph{at
most} an MA\((h-1)\) process \autocite{harvey1997,diebold2017}. We now
present the property under the assumption of a non-stationary
autoregressive DGP, and provide its proof in Section~\ref{sec-proof_ma}
based on the proof of Proposition~\ref{prp-ar} that we will introduce
later.

\begin{proposition}[MA\((h-1)\) process for \(h\)-step-ahead optimal
forecast errors]\protect\hypertarget{prp-ma}{}\label{prp-ma}

Let \(\{y_t\}_{t \geq 1}\) be a time series generated by a general
non-stationary autoregressive process as given in Equation~\ref{eq-dgp}.
Assume that the exogenous predictors are known into the future if
applicable. The forecast errors of optimal \(h\)-step-ahead forecasts
follow an approximate MA(\(h-1\)) process:

\[
e_{t+h|t} = m + \epsilon_{t+h} + \theta_1\epsilon_{t+h-1} + \cdots + \theta_{h-1}\epsilon_{t+1},
\]

where \(m=0\), motivated by the property that optimal forecasts are
unbiased.

\end{proposition}

We proceed by exploring the autocorrelations of multi-step forecast
errors for optimal forecasts.

\begin{proposition}[Autocorrelations of multi-step optimal forecast
errors]\protect\hypertarget{prp-ar}{}\label{prp-ar}

Let \(\{y_t\}_{t \geq 1}\) be a time series generated by a general
non-stationary autoregressive process as given in Equation~\ref{eq-dgp}.
Assume that the exogenous predictors are known into the future if
applicable. The forecast errors of optimal \(h\)-step-ahead forecasts
are \ul{at most} an approximate AR(\(h-1\)) process given by:

\begin{equation}\phantomsection\label{eq-ar}{
e_{t+h|t} = m + \epsilon_{t+h} + \phi_1e_{t+h-1|t} + \cdots + \phi_{h-1}e_{t+1|t},
}\end{equation}

where \(e_{t+h|t}\) is the \(h\)-step-ahead forecast error with variance
non-decreasing in \(h\), and the intercept \(m=0\), given the property
that optimal forecasts are unbiased.

\end{proposition}

Proposition~\ref{prp-ar} can be viewed as an extension of
Proposition~\ref{prp-ma}. It suggests that the \(h\)-step ahead forecast
error, \(e_{t+h|t}\), is serially correlated with the forecast errors
from at most the past \(h-1\) steps, i.e.,
\(e_{t+1|t}, \ldots, e_{t+h-1|t}\). However, we note that the
autocorrelation among errors associated with optimal forecasts can not
be used to improve forecasting performance, as it does not incorporate
any new information available when the forecast was made. It is
reasonable because if we could forecast the forecast error, we could
improve the forecast, indicating that the initial forecast couldn't have
been optimal.

The proof of Proposition~\ref{prp-ar} suggests that, if \(f_t\) is a
linear autoregressive model, then the AR coefficients in
Equation~\ref{eq-ar} are the linear coefficients of the optimal
forecasting model. However, when \(f_t\) takes on a more complex
nonlinear structure, the AR coefficients become complicated functions of
observed data and unobserved model coefficients.

\subsection{The AcMCP method}\label{sec-novel}

Inspired by the properties of multi-step forecast errors discussed in
Section~\ref{sec-ppt}, we now propose the \textbf{autocorrelated
multi-step conformal prediction} (AcMCP) method. Unlike extensions of
existing conformal prediction methods that treat multi-step forecasting
as independent events (see Section~\ref{sec-ext}), the AcMCP method
integrates the autocorrelations inherent in multi-step forecast errors,
thereby making the output multi-step prediction intervals more logically
structured.

The AcMCP method updates the quantile estimate \(q_t\) in an online
setting to achieve the goal of long-run coverage. Specifically, the
iteration of the \(h\)-step-ahead quantile estimate is given by

\begin{equation}\phantomsection\label{eq-acmcp}{
q_{t+h|t}=q_{t+h-1|t-1}+\eta \left(\mathrm{err}_{t|t-h}-\alpha\right)+r_t\left(\sum_{i=h+1}^t \left(\mathrm{err}_{i|i-h}-\alpha\right)\right)+\tilde{e}_{t+h|t},
}\end{equation}

for \(h\in[H]\). Obviously, the AcMCP method can be viewed as a further
extension of the PID method. Nevertheless, AcMCP diverges from PID with
several innovations and differences.

First, we are no longer confined to predicting just one step forward.
Instead, we can make multi-step forecasting with accompanying
theoretical coverage guarantees, constructing distribution-free
prediction intervals for steps \(t+1,\ldots,t+H\) based on available
information up to time \(t\). This is highly important in the field of
time series forecasting.

Additionally, in AcMCP, \(\tilde{e}_{t+h|t}\) is a forecast combination
of two simple models: one being an MA\((h-1)\) model trained on
\(h\)-step-ahead forecast errors available up to and including time
\(t\) (i.e.~\(e_{1+h|1}, \ldots, e_{t|t-h}\)), and the other an
AR\((h-1)\) model (with respect to \(h\) rather than \(t\)) trained by
regressing \(e_{t+h|t}\) on forecast errors from past steps
(i.e.~\(e_{t+h-1|t}, \ldots, e_{t+1|t}\)). Thus, we perform multi-step
conformal prediction recursively, contrasting with the independent
approach employed in MPID. Moreover, the inclusion of
\(\tilde{e}_{t+h|t}\) is not intended to forecast the nonconformity
scores (i.e., forecast errors in this paper), but rather to incorporate
autocorrelations present in multi-step forecast errors within the
resulting multi-step prediction intervals. As previously explained, in
the context of time series forecasting, we typically assume the use of a
good base forecasting model, making it unnecessary to train an
additional model to predict forecast errors in order to capture leftover
information. If the forecasts are not optimal, the base forecasting
model should be improved to enhance its performance.

\subsection{Coverage guarantees}\label{coverage-guarantees}

\begin{proposition}[]\protect\hypertarget{prp-cov_rt}{}\label{prp-cov_rt}

Let \(\{s_{t+h|t}\}_{t\in\mathbb{N}}\) be any sequence of numbers in
\([-b, b]\) for any \(h\in[H]\), where \(b>0\), and may be infinite.
Assume that \(r_t\) is a saturation function obeying
Equation~\ref{eq-saturation_h}, for an admissible function \(g\). Then
the iteration
\(q_{t+h|t}=r_t\left(\sum_{i=h+1}^t\left(\mathrm{err}_{i|i-h}-\alpha\right)\right)\)
satisfies

\begin{equation}\phantomsection\label{eq-cov_rt}{
\left|\frac{1}{T-h}\sum_{t=h+1}^{T}\left(\mathrm{err}_{t|t-h}-\alpha\right)\right| \leq \frac{c \cdot g(T-h) + h}{T-h},
}\end{equation}

for any \(T \geq h+1\), where \(c>0\) is the constant in
Equation~\ref{eq-saturation_h}.

In particular, this means the prediction intervals obtained by the
iteration yield long-run coverage, i.e.,
\(\lim _{T \rightarrow \infty} \frac{1}{T-h} \sum_{t=h+1}^T \mathrm{err}_{t|t-h} = \alpha\).

\end{proposition}

\textbf{Remark.} Proposition~\ref{prp-cov_rt} indicates that, for
\(t \ll \infty\), increasing the forecast horizon \(h\) tends to amplify
deviations from the target coverage because \(g(T-h)/(t-h)\) is
non-increasing, given that the admissible function \(g\) is sublinear,
nonnegative, and nondecreasing. This is consistent with expectations, as
extending the forecast horizon generally increases forecast uncertainty.
As predictions extend further into the future, more factors contribute
to variability and uncertainty. In this case, conformal prediction
intervals may not scale perfectly with the increasing uncertainty,
leading to a larger discrepancy between the desired and actual coverage.

The quantile iteration
\(q_{t+h|t}=q_{t+h-1|t-1}+\eta \left(\mathrm{err}_{t|t-h}-\alpha\right)\)
can be seen as a particular instance of the iteration outlined in
Proposition~\ref{prp-cov_rt} if we set \(q_{2h|h}=0\) without losing
generality. Thus, its coverage bounds can be easily derived as a result
of Proposition~\ref{prp-cov_rt}.

\begin{proposition}[]\protect\hypertarget{prp-cov_qt}{}\label{prp-cov_qt}

Let \(\{s_{t+h|t}\}_{t\in\mathbb{N}}\) be any sequence of numbers in
\([-b, b]\) for any \(h\in[H]\), where \(b>0\), and may be infinite.
Then the iteration
\(q_{t+h|t}=q_{t+h-1|t-1}+\eta \left(\mathrm{err}_{t|t-h}-\alpha\right)\)
satisfies

\[
\left|\frac{1}{T-h}\sum_{t=h+1}^{T}\left(\mathrm{err}_{t|t-h}-\alpha\right)\right| \leq \frac{b + \eta h}{\eta\left(T-h\right)},
\]

for any learning rate \(\eta > 0\) and \(T \geq h+1\).

In particular, this means the prediction intervals obtained by the
iteration yield long-run coverage, i.e.,
\(\lim _{T \rightarrow \infty} \frac{1}{T-h} \sum_{t=h+1}^T \mathrm{err}_{t|t-h} = \alpha\).

\end{proposition}

More importantly, Proposition~\ref{prp-cov_rt} is also adequate for
establishing the coverage guarantee of the proposed AcMCP method given
by Equation~\ref{eq-acmcp}. Following the idea of
\textcite{angelopoulos2024}, we first reformulate
Equation~\ref{eq-acmcp} as

\begin{equation}\phantomsection\label{eq-acmcp_1}{
q_{t+h|t}=\hat{q}_{t+h|t}+r_t\left(\sum_{i=h+1}^t \left(\mathrm{err}_{i|i-h}-\alpha\right)\right),
}\end{equation}

where \(\hat{q}_{t+h|t}\) can be any function of the past observations
\(\{(\bm{x}_i, y_i)\}_{1 \leq i \leq t}\) and quantile estimates
\(q_{i+h|i}\) for \(i \leq t-1\). Taking
\(\hat{q}_{t+h|t}=q_{t+h-1|t-1}+\eta \left(\mathrm{err}_{t|t-h}-\alpha\right)+\tilde{e}_{t+h|t}\)
will recover Equation~\ref{eq-acmcp}. We can consider
\(\hat{q}_{t+h|t}\) as the forecast of the quantile \(q_{t+h|t}\) based
on available historical data. We then present the coverage guarantee for
AcMCP given by Equation~\ref{eq-acmcp_1}.

\begin{proposition}[]\protect\hypertarget{prp-cov_acmcp}{}\label{prp-cov_acmcp}

Let \(\{\hat{q}_{t+h|t}\}_{t\in\mathbb{N}}\) be any sequence of numbers
in \([-\frac{b}{2}, \frac{b}{2}]\), and
\(\{s_{t+h|t}\}_{t\in\mathbb{N}}\) be any sequence of numbers in
\([-\frac{b}{2},\frac{b}{2}]\), for any \(h\in[H]\), \(b>0\) and may be
infinite. Assume that \(r_t\) is a saturation function obeying
Equation~\ref{eq-saturation_h}, for an admissible function \(g\). Then
the prediction intervals obtained by the AcMCP iteration given by
Equation~\ref{eq-acmcp_1} yield long-run coverage, i.e.,
\(\lim _{T \rightarrow \infty} \frac{1}{T-h} \sum_{t=h+1}^T \mathrm{err}_{t|t-h} = \alpha\).

\end{proposition}

\section{Experiments}\label{experiments}

In this section, we examine the empirical performance of the previously
proposed multi-step conformal prediction methods using two simulated
data settings and two real data examples.

Throughout the experiments, we adhere to the following parameter
settings: we focus on the target coverage level \(1-\alpha=0.9\); for
the MWCP method, we use \(b=0.99\) as per \textcite{barber2023};
following \textcite{angelopoulos2024}, we use a step size parameter of
\(\gamma=0.005\) for the MACP method, a Theta model as the scorecaster
in the MPID method, and a learning rate of \(\eta=0.01\hat{B}_t\) for
quantile tracking in the MPID and AcMCP methods, where
\(\hat{B}_t=\max\{s_{t-\Delta+1|t-\Delta-h+1},\cdots,s_{t|t-h}\}\) is
the highest score over a tailing window and the window length \(\Delta\)
is set to be same as the length of the calibration set; we adopt a
nonlinear saturation function defined as
\(r_t(x)=K_1 \tan \left(x \log (t) /\left(t C_{\text {sat }}\right)\right)\),
where \(\tan (x)=\operatorname{sign}(x) \cdot \infty\) for
\(x \notin[-\pi / 2, \pi / 2]\), and constants
\(C_{\text {sat }}, K_{\mathrm{I}}>0\) are chosen heuristically, as
suggested by \textcite{angelopoulos2024}; we consider a clipped version
of MACP by imputing infinite intervals with the largest score seen so
far.

\subsection{Simulated examples}\label{simulated-examples}

\subsubsection{Linear autoregressive
process}\label{linear-autoregressive-process}

We first consider a simulated stationary time series which is generated
from a simple AR\((2)\) process

\[
y_t = 0.8y_{t-1} - 0.5y_{t-2} + \epsilon_t,
\]

where \(\epsilon_t\) is white noise with error variance
\(\sigma^2 = 1\). After an appropriate burn-in period, we generate
\(N=5000\) data points. Under the sequential split and online learning
settings, we create training sets \(\mathcal{D}_{\text{tr}}\) and
calibration sets \(\mathcal{D}_{\text{cal}}\), each with a length of
\(500\). We use AR\((2)\) models to generate \(1\)- to \(3\)-step-ahead
point forecasts (i.e.~\(H=3\)) with the automated algorithm implemented
in the \textbf{forecast} R package \autocite{hyndman2024}. The goal is
to generate prediction intervals using various proposed conformal
prediction methods and evaluate whether they can achieve the nominal
long-run coverage for each separate forecast horizon.

Figure~\ref{fig-AR2_cov} presents the rolling coverage and interval
width of each method for each forecast horizon, with metrics computed
over a rolling window of size \(500\). In terms of coverage, we observe
that MPID and AcMCP achieve approximately the desired \(90\%\) coverage
level over the rolling windows, while other methods, including the AR
model, undergo much wider swings away from the desired level, showing
large troughs and peaks in coverage as time changes. Turning to the
prediction interval width, the trajectories of the rolling mean and
median of the interval widths for each method are largely consistent.
AcMCP constructs narrower prediction intervals than MPID, despite both
methods achieving similar coverage. Moreover, we see that AcMCP tends to
offer adaptive prediction intervals, and results in wider intervals
especially when competing methods undercover, which is to be expected.
In short, AcMCP intervals offer greater adaptivity and more precise
coverage compared to AR, MSCP, MWCP and MACP. However, MPID achieves
tight coverage but at the cost of constructing wider prediction
intervals. This is due to the fact that the inclusion of a second model
(scorecaster) is likely to introduce large variance into the generated
prediction intervals. The results can be further elucidated with
Figure~\ref{fig-AR2_box}, which presents boxplots of rolling coverage
and interval width for each method and each forecast horizon.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-AR2_cov-1.pdf}

}

\caption{\label{fig-AR2_cov}AR(2) simulation results showing rolling
coverage, mean and median interval width for each forecast horizon. The
displayed curves are smoothed over a rolling window of size \(500\). The
black dashed line indicates the target level of \(1-\alpha=0.9\).}

\end{figure}%

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-AR2_box-1.pdf}

}

\caption{\label{fig-AR2_box}AR(2) simulation results showing boxplots of
the rolling coverage and interval width for each method across different
forecast horizons. The red dashed lines show the target coverage level,
while the blue dashed lines indicate the median interval width of the
AcMCP method.}

\end{figure}%

We note that the inclusion of the last term \(\tilde{e}_{t+h|t}\) in
AcMCP should only result in a slight difference compared to the version
without this term, which we henceforth refer to as MPI. This is because,
the inclusion of \(\tilde{e}_{t+h|t}\) aims to capture autocorrelations
inherent in multi-step forecast errors and focuses on the mean of
forecast errors, whereas the whole update of AcMCP operates on quantiles
of scores. To illustrate the subtle difference in their results and
explore their origins, we visualize their prediction interval over a
truncated period of length \(500\), as shown in
Figure~\ref{fig-AR2_timeplot}. We observe that AcMCP and MPI indeed
construct similar prediction intervals so their lower and upper bounds
mostly overlap with each other. The main differences may occur around
the time 1320 and during the period 1470-1500, where AcMCP tends to have
a fanning-out effect, increasing the interval width as the forecast
horizon increases, compared to MPI. Figure~\ref{fig-AR2_timeplot} also
presents the prediction interval bounds given by MACP. The prediction
intervals of both AcMCP and MACP can capture certain patterns in the
actual observations, and there is no consistent pattern indicating
dominance of one method over the other in terms of interval width.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-AR2_timeplot-1.pdf}

}

\caption{\label{fig-AR2_timeplot}AR(2) simulation results showing the
prediction interval bounds for the MACP, MPI, and AcMCP methods over a
truncated period of length 500.}

\end{figure}%

\subsubsection{Nonlinear autoregressive
process}\label{nonlinear-autoregressive-process}

We then consider the case of a nonlinear data generation process, which
happens in many practical time series applications. We specify the true
DGP as

\[
y_t = \sin(y_{t-1}) + 0.5\log(y_{t-2} + 1) + 0.1y_{t-1}x_{1,t} + 0.3x_{2,t} + \epsilon_{t},
\]

where \(x_{1,t}\) and \(x_{2,t}\) are uniformly distributed on
\([0,1]\), and \(\epsilon_{t}\) is white noise with error variance
\(\sigma^2 = 0.1\). Thus, the time series \(y_t\) nonlinearly depends on
its lagged values \(y_{t-1}\) and \(y_{t-2}\), as well as exogenous
variables \(x_{1,t}\) and \(x_{2,t}\).

After an appropriate burn-in period, we generate \(N=2000\) data points.
Under the sequential split and online learning settings, we create
training sets \(\mathcal{D}_{\text{tr}}\) and calibration sets
\(\mathcal{D}_{\text{cal}}\), each with a length of \(500\). Given the
nonlinear structure of the DGP, we use feed-forward neural networks with
a single hidden layer and lagged inputs to generate \(1\)- to
\(3\)-step-ahead point forecasts (i.e.~\(H=3\)) with the automated
algorithm implemented in the \textbf{forecast} R package. Note that it
is not straightforward for neural networks to derive interval forecasts,
thus we do not include neural network models when presenting the
results.

Figure~\ref{fig-NL_cov} illustrates the rolling coverage and interval
width of each method, with calculations based on a rolling window of
size \(100\). We see that MPID and AcMCP are able to maintain minor
fluctuations around the target coverage of \(90\%\) across all time
indices, contrasting with MSCP, MWCP, and MACP, which struggle to
sustain the target coverage and display pronounced fluctuations over
time. Moreover, all conformal prediction methods, except for MSCP,
construct adaptive prediction intervals. They widen intervals in
response to undercoverage and narrow them when overcoverage occurs.
Notably, MPID and AcMCP demonstrate greater adaptability, displaying
higher variability in interval widths compared to competing methods in
order to uphold the desired coverage. Lastly, AcMCP intervals are
evidently narrower than MPID intervals for \(2\)-step-ahead forecasting
but wider for \(3\)-step-ahead forecasting. AcMCP intervals appear to be
more reasonable, as they tend to widen with increasing forecast
horizons.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-NL_cov-1.pdf}

}

\caption{\label{fig-NL_cov}Nonlinear simulation results showing rolling
coverage, mean and median interval width for each forecast horizon. The
displayed curves are smoothed over a rolling window of size \(100\). The
black dashed line indicates the target level of \(1-\alpha=0.9\).}

\end{figure}%

We provide further insights into the performance of these conformal
prediction methods by presenting boxplots of the rolling coverage and
interval width for each method, as depicted in Figure~\ref{fig-NL_box}.
We observe that coverage variability is higher for MSCP, MWCP and MACP
than for MPID and AcMCP, while MPID and AcMCP lead to a lower effective
interval size.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-NL_box-1.pdf}

}

\caption{\label{fig-NL_box}Nonlinear simulation results showing boxplots
of the rolling coverage and interval width for each method across
different forecast horizons. The red dashed lines show the target
coverage level, while the blue dashed lines indicate the median interval
width of the AcMCP method.}

\end{figure}%

\subsection{Real data examples}\label{real-data-examples}

\subsubsection{Electricity demand data}\label{electricity-demand-data}

Now we examine empirical performance of the conformal prediction methods
using an electricity demand data set. The data set tracks daily
electricity demand (GW), daily maximum temperature (degrees Celsius),
and holiday information for the state of Victoria, Australia, spanning a
three-year period from 2012 to 2014. The left panel of
Figure~\ref{fig-elec_data} displays the daily electricity demand during
2012-2014, along with temperatures. The right panel shows a nonlinear
relationship between electricity demand and temperature, with demand
increasing for low temperatures (due to heating) and increasing for high
temperatures (due to cooling).

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-elec_data-1.pdf}

}

\caption{\label{fig-elec_data}Daily electricity demand and corresponding
daily maximum temperatures in 2012--2014, Victoria, Australia.}

\end{figure}%

Our response variable is \(\texttt{Demand}\), and we use two covariates:
\(\texttt{Temperature}\), and \(\texttt{Workday}\) (an indicator
variable for if the day was a working day or not). Following
\textcite{hyndman2021}, we will fit a dynamic regression model with a
piecewise linear function of temperature (containing a knot at \(18\)
degrees) to generate \(1\)- to \(7\)-step-ahead point forecasts
(i.e.~\(H=7\)). The error series in the regression is assumed to follow
an ARIMA model to contain autocorrelation. We use two years of data as
training sets to fit dynamic regression models, and use \(100\) data
points for calibration sets.

We present the results in Figure~\ref{fig-elec_cov} and
Figure~\ref{fig-elec_box}, comparing the rolling coverage and interval
width of each method. These computations are based on a rolling window
of size \(100\). First, we observe that DR (dynamic regression)
consistently achieves a significantly higher coverage than the \(90\%\)
target coverage, resulting in much wider intervals than other methods
for \(h=1,2,3,4\). Secondly, MSCP, MWCP, and MACP fail to sustain the
target coverage and noticeably undercover after September 2014 for all
forecast horizons, thus leading to narrower intervals than others.
Thirdly, MPI, MPID, and AcMCP offer prediction intervals that are wider
than those of other conformal prediction methods, effectively mitigating
or avoiding the undercoverage issue observed after September 2014.
Additionally, we notice that MPID performs slightly worse than MPI and
AcMCP in terms of coverage for \(h=3,4,7\), despite leading to wider
intervals. Finally, MPI and AcMCP coverage display similar pattern, but
AcMCP is capable of constructing narrower intervals than MPI.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-elec_cov-1.pdf}

}

\caption{\label{fig-elec_cov}Electricity demand data results showing
rolling coverage, mean and median interval width for each forecast
horizon. The displayed curves are smoothed over a rolling window of size
\(100\). The black dashed line indicates the target level of
\(1-\alpha=0.9\).}

\end{figure}%

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-elec_box-1.pdf}

}

\caption{\label{fig-elec_box}Electricity demand data results showing
boxplots of the rolling coverage and interval width for each method
across different forecast horizons. The red dashed lines show the target
coverage level, while the blue dashed lines indicate the median interval
width of the AcMCP method.}

\end{figure}%

We present the forecast interval bounds for MACP, MPI, and AcMCP in
Figure~\ref{fig-elec_timeplot}. The plot shows that MACP intervals are
too narrow to adequately hug the true values, particularly from
September to November of 2014. In contrast, MPI and AcMCP perform better
by widening their intervals, resulting in narrower swings away from the
\(90\%\) target level. The differences between MPI and AcMCP prediction
intervals are most pronounced in the \(5\)-, \(6\)-, and
\(7\)-step-ahead forecast results. For \(5\)-step-ahead forecasting,
from May to July of 2014, the upper bounds of MPI intervals struggle to
capture the true values. AcMCP addresses this undercoverage by construct
larger upper bounds. In August and September, AcMCP constructs smaller
upper bounds than MPI while still capturing the true values effectively.
For \(6\)-step-ahead forecasting from May to July, AcMCP offers smaller
upper bounds than MPI, which provides upper bounds that are far away
from the truth. Similar reaction is observed for \(7\)-step-ahead
forecasting during August and September.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-elec_timeplot-1.pdf}

}

\caption{\label{fig-elec_timeplot}Electricity demand data results
showing the forecast interval bounds for MACP, MPI, and AcMCP over the
whole test set.}

\end{figure}%

\subsubsection{Eating out expenditure
data}\label{eating-out-expenditure-data}

Finally, we apply the conformal prediction methods to predict the eating
out expenditure (\$million) in Victoria, Australia. The data set
includes monthly expenditure on cafes, restaurants and takeaway food
services in Victoria from April 1982 up to December 2019, as shown in
Figure~\ref{fig-cafe_data}. The data shows an overall upward trend,
obvious annual seasonal patterns, and variability proportional to the
data level.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-cafe_data-1.pdf}

}

\caption{\label{fig-cafe_data}Monthly expenditure on cafes, restaurants
and takeaway food services in Victoria, Australia, from April 1982 to
December 2019.}

\end{figure}%

We consider three models: ARIMA with logarithmic transformation, ETS,
and STL-ETS \autocite{hyndman2021}, and then output their simple average
as final point forecasts. STL-ETS involves forecasting using the STL
decomposition method, applying ETS to forecast the seasonally adjusted
series. All three models can be automatically trained using the
\textbf{forecast} R package. Our goal is to forecast \(12\) months
ahead, i.e.~\(H=12\). We use \(20\) years of data for training the
models and \(5\) years of data for calibration sets. The whole test set
only has a length of \(152\) months. Therefore, we will not compute
rolling coverage and interval width in this experiment, but rather
compute the coverage and interval width averaged over the entire test
set.

We summarize the average coverage and interval width for each method and
each forecast horizon in Figure~\ref{fig-cafe_cov}. The results first
show that MSCP, MWCP and MACP provide valid prediction intervals for
smaller forecast horizon but fail to achieve the desired coverage for
larger forecast horizons (\(h>5\)). Secondly, for \(h \leq 5\), MPI and
AcMCP can approximately achieve the desired coverage and provide
comparable mean interval widths with other methods, except for MPID.
Thirdly, the coverage of MSCP, MWCP and MACP declines gradually as the
forecast horizon increases, while MPI and AcMCP maintain coverage within
a tighter range, albeit at the cost of interval efficiency. Lastly,
compared to MPI, AcMCP exhibits slightly less deviation from the desired
coverage across most forecast horizons.

\begin{figure}

\centering{

\includegraphics{cpts_files/figure-pdf/fig-cafe_cov-1.pdf}

}

\caption{\label{fig-cafe_cov}Eating out expenditure data results showing
coverage gap and interval width averaged over the entire test set for
each forecast horizon. The black dashed line in the top panel indicates
no difference from the \(90\%\) target level.}

\end{figure}%

\section{Conclusion and discussion}\label{conclusion-and-discussion}

This paper establishes a unified notation to formalize the mathematical
representation of conformal prediction specifically within the context
of time series data. We focus specifically on conformal inference for
multi-step time series forecasting in a generic online learning
framework. To begin, we extend several accessible conformal prediction
methods to address the challenges of multi-step forecasting scenarios.

We prove that the optimal multi-step-ahead forecast errors can be
approximated by an AR process under the assumption of a general
non-stationary autoregressive DGP. Building on this foundation, we
introduce a novel method, AcMCP, which accounts for the autocorrelations
inherent in multi-step forecast errors. We indicate that as the forecast
horizon increases, deviations from the target coverage also tend to
increase. Notably, our method achieves long-run coverage guarantees
without imposing assumptions regarding data distribution shifts. On both
simulations and real-world experiments, our proposed method achieves
coverage closer to the target within local windows while offering
adaptive prediction intervals that respond effectively to varying
conditions.

We also discuss the limitations of our work. Notably, we restrict our
focus to ex-post forecasting, operating under the assumption that actual
observations of the exogenous predictors during the forecast period are
accessible. Additionally, our methodology does not incorporate an
algorithmic approach to tuning the learning rate parameter. These
considerations pave the way for numerous avenues for future research.
Potential directions include the introduction of a time-dependent
learning rate parameter to minimize interval width while maintaining the
guaranteed coverage rate, as well as the development of refined
methodologies that account for variability introduced by forecasting
predictors in ex-ante scenarios.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\printbibliography[heading=none]

\newpage
\appendix
% \pagenumbering{arabic}% resets `page` counter to 1
\setcounter{section}{0}
\renewcommand{\thesection}{Appendix \Alph{section}}
\renewcommand{\thesubsection}{\Alph{section}.\arabic{subsection}}
\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

\section{Weighted quantile estimation}\label{appendix-wq}

\begin{itemize}
\tightlist
\item
  median-unbiased estimates
\end{itemize}

\section{Proof}\label{sec-proof}

\subsection{\texorpdfstring{Proof of
Proposition~\ref{prp-ma}}{Proof of Proposition~}}\label{sec-proof_ma}

\begin{proof}
Here, we give the proof of Proposition~\ref{prp-ma} based on
Proposition~\ref{prp-ar}, and the idea is motivated by
\textcite{sommer2023}.

For \(1\)-step-ahead optimal forecast, we have

\[
y_{t+1} = f_{t+1}(y_{(t-d+1):t},\bm{x}_{(t-k+1):(t+1)}) + \epsilon_{t+1},
\]

so \(e_{t+1|t}=\epsilon_{t+1}\).

Based on Proposition~\ref{prp-ar}, we have

\[
\begin{aligned}
e_{t+2|t} &= \epsilon_{t+2} + \phi_{1}^{(2)}e_{t+1|t} \\
e_{t+3|t} &= \epsilon_{t+3} + \phi_{1}^{(3)}e_{t+2|t} + \phi_{2}^{(3)}e_{t+1|t} \\
\cdots \\
e_{t+d|t} &= \epsilon_{t+d} + \phi_{1}^{(d)}e_{t+d-1|t} + \cdots + \phi_{d-1}^{(d)}e_{t+1|t} \\
e_{t+d+1|t} &= \epsilon_{t+d+1} + \phi_{1}^{(d+1)}e_{t+d|t} + \cdots + \phi_{d-1}^{(d+1)}e_{t+2|t} + \phi_{d}^{(d+1)}e_{t+1|t} \\
\cdots \\
e_{t+H|t} &= \epsilon_{t+H} + \phi_{1}^{(H)}e_{t+H-1|t} + \cdots + \phi_{d-1}^{(H)}e_{t+H-d+1|t} + \phi_{d}^{(H)}e_{t+H-d|t}, \quad H > d + 1. \\
\end{aligned}
\]

Substituting all equations above into the following equation, we can
obtain

\[
e_{t+h|t} = \epsilon_{t+h} + \sum_{i=1}^{h-1}\theta_{i}\epsilon_{t+h-i}, \text{ for each } h\in[H],
\]

where \(\theta_{i}\) is a complex function derived from the AR
coefficients of all AR\((j-1)\) models, for \(j = 1,2,\ldots,h-1\). So
we conclude that the \(h\)-step-ahead forecast error sequence
\(\{e_{t+h|t}\}\) follows an MA\((h-1)\) process.
\end{proof}

\subsection{\texorpdfstring{Proof of
Proposition~\ref{prp-ar}}{Proof of Proposition~}}\label{sec-proof_ar}

\begin{proof}
Let \(\hat{y}_{t+h|t}\) be the optimal \(h\)-step-ahead point forecast,
and \(e_{t+h|t}\) be the \(h\)-step-ahead forecast error. Denote
\(\bm{u}_{t+h}=\bm{x}_{(t-k+h):(t+h)}\). Then we have

\[
\begin{aligned}
\hat{y}_{t+h|t}=\begin{cases}
      f_{t+1}\left(y_t,\cdots,y_{t-d+1},\bm{u}_{t+1}\right) & \text{ if } h=1, \\
      f_{t+h}\left(\hat{y}_{t+h-1|t},\cdots,\hat{y}_{t+1|t},y_t,\cdots,y_{t+h-d},\bm{u}_{t+h}\right) &  \text{ if } 1 < h \leq d, \\
      f_{t+h}\left(\hat{y}_{t+h-1|t},\cdots,\hat{y}_{t+h-d|t},\bm{u}_{t+h}\right) & \text{ if } h > d.\\
    \end{cases}\\
\end{aligned}
\]

For \(h=1\), we simply have \(e_{t+1|t} = \epsilon_{t+1}\).

For \(1<h\leq d\), applying the first order Taylor series expansion, we
can write

\[
\begin{aligned}
y_{t+h}
=&f_{t+h}\left(y_{t+h-1},\cdots,y_{t+h-d},\bm{u}_{t+h}\right)+\epsilon_{t+h} \\
=&f_{t+h}\left(\hat{y}_{t+h-1|t}+e_{t+h-1|t},\cdots,\hat{y}_{t+1|t}+e_{t+1|t},y_{t},\cdots,y_{t+h-d},\bm{u}_{t+h}\right)+\epsilon_{t+h} \\
\underset{\text{te}}{\approx}&f_{t+h}\left(\bm{a}\right)+\operatorname{D}f_{t+h}\left(\bm{a}\right)\left(\bm{v}-\bm{a}\right)+
\epsilon_{t+h} \\
=&f_{t+h}\left(\hat{y}_{t+h-1|t},\cdots,\hat{y}_{t+1|t},y_{t},\cdots,y_{t+h-d},\bm{u}_{t+h}\right) \\
&+e_{t+h-1|t}\frac{\partial f_{t+h}\left(\bm{a}\right)}{\partial v_1}+\cdots+e_{t+2|t}\frac{\partial f_{t+h}\left(\bm{a}\right)}{\partial v_{h-2}}+e_{t+1|t}\frac{\partial f_{t+h}\left(\bm{a}\right)}{\partial v_{h-1}}+\epsilon_{t+h} \\
=&\hat{y}_{t+h|t}+e_{t+h|t},
\end{aligned}
\]

where \(\bm{v}=\left(y_{t+h-1},\cdots,y_{t+h-d},\bm{u}_{t+h}\right)\),
\(\bm{a} =\left(\hat{y}_{t+h-1|t},\cdots,\hat{y}_{t+1|t},y_{t},\cdots,y_{t+h-d},\bm{u}_{t+h}\right)\),
\(\operatorname{D}f_{t+h}\left(\bm{a}\right)\) denotes the matrix of
partial derivative of \(f_{t+h}(\bm{v})\) at \(\bm{v}=\bm{a}\), and
\(\frac{\partial}{\partial v_i}\) denotes the partial derivative with
respect to the \(i\)th component in \(f_{t+h}\).

Similarly, for \(h > d\), we can write

\[
\begin{aligned}
y_{t+h}
=&f_{t+h}\left(y_{t+h-1},\cdots,y_{t+h-d},\bm{u}_{t+h}\right)+\epsilon_{t+h} \\
=&f_{t+h}\left(\hat{y}_{t+h-1|t}+e_{t+h-1|t},\cdots,\hat{y}_{t+h-d|t}+e_{t+h-d|t},\bm{u}_{t+h}\right)+\epsilon_{t+h} \\
\underset{\text{te}}{\approx}&f_{t+h}\left(\bm{a}\right)+\operatorname{D}f_{t+h}\left(\bm{a}\right)\left(\bm{v}-\bm{a}\right)+
\epsilon_{t+h} \\
=&f_{t+h}\left(\hat{y}_{t+h-1|t},\cdots,\hat{y}_{t+h-d|t},\bm{u}_{t+h}\right) \\
&+e_{t+h-1|t}\frac{\partial f_{t+h}\left(\bm{a}\right)}{\partial v_1}+e_{t+h-d|t}\frac{\partial f_{t+h}\left(\bm{a}\right)}{\partial v_{d}}+\epsilon_{t+h} \\
=&\hat{y}_{t+h|t}+e_{t+h|t},
\end{aligned}
\]

Therefore, the forecast errors of optimal \(h\)-step-ahead forecasts are
at most an approximate AR(\(h-1\)) process.
\end{proof}

\subsection{\texorpdfstring{Proof of
Proposition~\ref{prp-cov_rt}}{Proof of Proposition~}}\label{sec-proof_cov_rt}

\begin{proof}
Let \(E_T=\sum_{t=h+1}^{T}\left(\mathrm{err}_{t|t-h}-\alpha\right)\).
The inequality given by Equation~\ref{eq-cov_rt} can be expressed as
\(\left|E_T\right| \leq c \cdot g(T-h) + h\). We will prove one side of
the absolute inequality, specifically \(E_T \leq c \cdot g(T-h) + h\),
with the other side following analogously. We proceed with the proof
using induction.

For \(T=h+1,\ldots,2h\),
\(E_T = \sum_{t=h+1}^{T}(\mathrm{err}_{t|t-h}-\alpha) \leq (T-h)-(T-h)\alpha \leq T-h \leq h \leq cg(T-h) + h\)
as \(c>0\), \(h\geq 1\), \(g\) is nonnegative, and
\(\mathrm{err}_{t|t-h} \leq 1\). Thus, Equation~\ref{eq-cov_rt} holds
for \(T=h+1,\ldots,2h\).

Now, assuming Equation~\ref{eq-cov_rt} is true up to \(T\). We partition
the argument into \(h+1\) cases:

\[
\begin{cases}
cg(T-h)+h-1 < E_T \leq cg(T-h)+h, & \ldots \text { case (1) } \\
cg(T-h)+h-2 < E_T \leq cg(T-h)+h-1, & \ldots \text { case (2) } \\
\qquad \cdots \\
cg(T-h) < E_T \leq cg(T-h)+1, & \ldots \text { case (h) } \\
E_T \leq cg(T-h). & \ldots \text { case (h+1) }
\end{cases}
\]

In case (1), we observe that \(E_T > cg(T-h)+h-1 > cg(T-h)\), implying
\(q_{T+h|T} = r_t(E_{T}) \geq b\) according to
Equation~\ref{eq-saturation_h}. Thus, \(s_{T+h|T} \leq q_{T+h|T}\) and
\(\mathrm{err}_{T+h|T} = 0\). Furthermore, we have
\(E_{T-1} = E_T - (\mathrm{err}_{T|T-h} - \alpha) > cg(T-h)+h-2 > cg(T-h-1)\)
as \(g\) is nondecreasing. This implies
\(q_{T+h-1|T-1} = r_t(E_{T-1}) \geq b\), hence
\(s_{T+h-1|T-1} \leq q_{T+h-1|T-1}\) and
\(\mathrm{err}_{T+h-1|T-1} = 0\). Similarly,
\(E_{T-2} = E_{T-1} - (\mathrm{err}_{T-1|T-h-1} - \alpha) > cg(T-h)+h-3 > cg(T-h-2)\),
thus \(\mathrm{err}_{T+h-2|T-2} = 0\). This process iterates, leading to
\(\mathrm{err}_{T+h|T} = \mathrm{err}_{T+h-1|T-1} = \cdots = \mathrm{err}_{T+1|T-h+1} = 0\).
Consequently,

\[
E_{T+h} = E_T+\sum_{t=T+1}^{T+h}(\mathrm{err}_{t|t-h}-\alpha) \leq cg(T-h)+h-h\alpha \leq cg(T)+h,
\]

which is the desired result at \(T+h\).

In case (2), we observe that \(E_T > cg(T-h)+h-2 > cg(T-h)\), thus
\(s_{T+h|T} \leq q_{T+h|T}\) and \(\mathrm{err}_{T+h|T} = 0\). Moving
forward, we have
\(\mathrm{err}_{T+h|T} = \mathrm{err}_{T+h-1|T-1} = \cdots = \mathrm{err}_{T+2|T-h+2} = 0\).
Along with \(\mathrm{err}_{T+1|T-h+1} \leq 1\), this means that

\[
E_{T+h} = E_T+\sum_{t=T+1}^{T+h}(\mathrm{err}_{t|t-h}-\alpha) \leq cg(T-h)+h-1+1-h\alpha \leq cg(T)+h,
\]

which again gives the desired result at \(T+h\).

Similarly, in cases (3)-(h), we can always get the desired result at
\(T+h\).

In case (h+1), noticing \(E_T \leq cg(T-h)\), and simply using
\(\mathrm{err}_{T+h-i|T-i} \leq 1\) for \(i=0,\ldots,h-1\), we have

\[
E_{T+h} = E_T+\sum_{t=T+1}^{T+h}(\mathrm{err}_{t|t-h}-\alpha) \leq cg(T-h)+h-h\alpha \leq cg(T)+h.
\]

Therefore, we can deduce the desired outcome at any \(T \geq h+1\). This
completes the proof for the first part of Proposition~\ref{prp-cov_rt}.

Regarding the second part, \(g(t-h)/(t-h) \rightarrow 0\) as
\(t \rightarrow \infty\) due to the sublinearity of the admissible
function \(g\). Hence the second part holds trivially.
\end{proof}

\subsection{\texorpdfstring{Proof of
Proposition~\ref{prp-cov_qt}}{Proof of Proposition~}}\label{sec-proof_cov_qt}

\begin{proof}
We set \(q_{2h|h}=0\) without losing generality, the iteration
\(q_{t+h|t}=q_{t+h-1|t-1}+\eta \left(\mathrm{err}_{t|t-h}-\alpha\right)\)
simplifies to
\(q_{t+h|t}=\eta \sum_{i=h+1}^{t}\left(\mathrm{err}_{i|i-h}-\alpha\right)\).
Let \(r_t(x) = \eta x\) and the admissible function \(g(t-h) = b\),
Equation~\ref{eq-saturation_h} holds for \(c=\frac{1}{\eta}\). Then
Proposition~\ref{prp-cov_rt} applies and we can easily derive the
desired result.
\end{proof}

\subsection{\texorpdfstring{Proof of
Proposition~\ref{prp-cov_acmcp}}{Proof of Proposition~}}\label{sec-proof_cov_acmcp}

\begin{proof}
Let \(q_{t+h|t}^{*}=q_{t+h|t}-\hat{q}_{t+h|t}\), then
Equation~\ref{eq-acmcp_1} transforms into an update process
\(q_{t+h|t}^{*}=r_t\left(\sum_{i=h+1}^t \left(\mathrm{err}_{i|i-h}-\alpha\right)\right)\),
which is an update with respect to \(q_{t+h|t}^{*}\). Under this new
framework, the nonconformity score becomes
\(s_{t+h|t}^{*}=s_{t+h|t}-\hat{q}_{t+h|t}\), with values ranging in
\([-b,b]\), given the assumption that both \(s_{t+h|t}\) and
\(\hat{q}_{t+h|t}\) fall within \([-\frac{b}{2},\frac{b}{2}]\). Thus,
Proposition~\ref{prp-cov_rt} can be directly applied to establish the
long-run coverage achieved by the AcMCP method.
\end{proof}





\end{document}
